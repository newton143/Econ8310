{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdZw72DF6wEeVhPQ15vmck",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newton143/Econ8310/blob/master/NeuralNetwork_Lesson7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TdqdEimzfgs6"
      },
      "outputs": [],
      "source": [
        "# For reading data\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# For visualizing\n",
        "import plotly.express as px\n",
        "\n",
        "# For model building\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomMNIST(Dataset):\n",
        "    def __init__(self, url):\n",
        "        # read in our raw data from the hosting URL\n",
        "        self.raw_data = pd.read_csv(url)\n",
        "\n",
        "    # return the length of the complete data set\n",
        "    #   to be used in internal calculations for pytorch\n",
        "    def __len__(self):\n",
        "        return self.raw_data.shape[0]\n",
        "\n",
        "    # retrieve a single record based on index position `idx`\n",
        "    def __getitem__(self, idx):\n",
        "        # extract the image separate from the label\n",
        "        image = self.raw_data.iloc[idx, 1:].values.reshape(1, 28, 28)\n",
        "        # Specify dtype to align with default dtype used by weight matrices\n",
        "        image = torch.tensor(image, dtype=torch.float32)\n",
        "        # extract the label\n",
        "        label = self.raw_data.iloc[idx, 0]\n",
        "\n",
        "        # return the image and its corresponding label\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "oZpny3Fzfzza"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wRZHxwVFf5GV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load our data into memory\n",
        "train_data = CustomMNIST(\"https://github.com/dustywhite7/Econ8310/raw/master/DataSets/mnistTrain.csv\")\n",
        "test_data = CustomMNIST(\"https://github.com/dustywhite7/Econ8310/raw/master/DataSets/mnistTest.csv\")\n",
        "\n",
        "# Create data feed pipelines for modeling\n",
        "train_dataloader = DataLoader(train_data, batch_size=64)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64)"
      ],
      "metadata": {
        "id": "YkqPZfp4gDOw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that our data look right when we sample\n",
        "\n",
        "idx=1\n",
        "print(f\"This image is labeled a {train_data.__getitem__(idx)[1]}\")\n",
        "px.imshow(train_data.__getitem__(idx)[0].reshape(28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "Sy5aJk67gQuX",
        "outputId": "2f417b91-0272-4856-c876-a113cf4cc11b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This image is labeled a 9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"66f330cd-ce58-4cd4-9b87-f4b5a29b5ebd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"66f330cd-ce58-4cd4-9b87-f4b5a29b5ebd\")) {                    Plotly.newPlot(                        \"66f330cd-ce58-4cd4-9b87-f4b5a29b5ebd\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1882353,0.85490197,0.99215686,0.92941177,0.5803922,0.1882353,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.26666668,0.74509805,0.96862745,0.9882353,0.9882353,0.99215686,0.9882353,0.93333334,0.25098038,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.023529412,0.25882354,0.9607843,0.9882353,0.9490196,0.627451,0.49411765,0.5647059,0.93333334,0.9882353,0.96862745,0.7372549,0.03529412,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5254902,0.9882353,0.99215686,0.76862746,0.16470589,0.0,0.0,0.0,0.25098038,0.96862745,0.9882353,0.9882353,0.5568628,0.16862746,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.21176471,0.8,0.9882353,0.7490196,0.21176471,0.0,0.0,0.0,0.0,0.0,0.39215687,0.9882353,0.9882353,0.99215686,0.9372549,0.41568628,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.9137255,0.99215686,0.9254902,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.105882354,0.654902,0.99607843,0.99215686,0.9607843,0.2627451,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.39215687,0.96862745,0.9882353,0.26666668,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7254902,0.99215686,0.9882353,0.9882353,0.7411765,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.015686275,0.42352942,0.9882353,0.96862745,0.14901961,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4862745,0.99215686,0.9882353,0.9882353,0.96862745,0.49803922,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.12549019,0.92941177,0.9882353,0.5686275,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7254902,0.99215686,0.9882353,0.9882353,0.8862745,0.09411765,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.3137255,0.9490196,0.95686275,0.43529412,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.105882354,0.654902,0.99215686,0.9882353,0.9882353,0.8862745,0.09411765,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.3137255,0.9529412,0.9607843,0.43529412,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.015686275,0.7176471,0.99215686,1.0,0.85490197,0.77254903,0.13725491,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.07058824,0.84705883,0.9882353,0.7411765,0.0,0.0,0.0,0.0,0.0,0.0,0.05882353,0.4745098,0.7647059,0.9882353,0.9882353,0.99215686,0.7411765,0.019607844,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.36862746,0.9882353,0.96862745,0.5647059,0.050980393,0.08627451,0.08627451,0.36078432,0.49803922,0.7529412,0.9882353,0.9843137,0.92941177,0.9882353,0.99215686,0.62352943,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.25098038,0.8666667,0.9882353,0.9882353,0.85490197,0.9882353,0.9882353,0.9882353,0.9882353,0.99215686,0.9882353,0.5254902,0.42352942,0.9882353,0.99215686,0.24705882,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.08235294,0.5411765,0.9882353,0.99215686,0.9882353,0.9882353,0.7137255,0.5764706,0.5058824,0.16470589,0.015686275,0.42352942,0.9882353,0.9254902,0.14509805,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03529412,0.8,0.99215686,0.9019608,0.105882354,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.062745094,0.9098039,0.9882353,0.5137255,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.050980393,0.7137255,0.9882353,0.7607843,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39607844,0.9882353,0.9882353,0.5176471,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.25882354,0.9882353,0.9882353,0.4862745,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('66f330cd-ce58-4cd4-9b87-f4b5a29b5ebd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FirstNet(nn.Module):\n",
        "    def __init__(self):\n",
        "      # We define the components of our model here\n",
        "      super(FirstNet, self).__init__()\n",
        "      # Function to flatten our image\n",
        "      self.flatten = nn.Flatten()\n",
        "      # Create the sequence of our network\n",
        "      self.linear_relu_model = nn.Sequential(\n",
        "            # Add a linear output layer w/ 10 perceptrons\n",
        "            nn.LazyLinear(10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      # We construct the sequencing of our model here\n",
        "      x = self.flatten(x)\n",
        "      # Pass flattened images through our sequence\n",
        "      output = self.linear_relu_model(x)\n",
        "\n",
        "      # Return the evaluations of our ten\n",
        "      #   classes as a 10-dimensional vector\n",
        "      return output\n"
      ],
      "metadata": {
        "id": "65bIXuyKgLWm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of our model\n",
        "model = FirstNet()"
      ],
      "metadata": {
        "id": "kN4LN2eDgbDI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define some training parameters\n",
        "learning_rate = 1e-2\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "\n",
        "# Define our loss function\n",
        "#   This one works for multiclass problems\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "DWU-FQCUgsXW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define some training parameters\n",
        "learning_rate = 1e-2\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "\n",
        "# Define our loss function\n",
        "#   This one works for multiclass problems\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Gx2LbbArgu8m"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build our optimizer with the parameters from\n",
        "#   the model we defined, and the learning rate\n",
        "#   that we picked\n",
        "optimizer = torch.optim.SGD(model.parameters(),\n",
        "     lr=learning_rate)"
      ],
      "metadata": {
        "id": "bUFr3M3Pgynp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    # Set the model to training mode\n",
        "    # important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.train()\n",
        "    # Loop over batches via the dataloader\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation and looking for improved gradients\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Zeroing out the gradient (otherwise they are summed)\n",
        "        #   in preparation for next round\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Print progress update every few loops\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "JQB1J6ggg3PK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "    # Set the model to evaluation mode\n",
        "    # important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures\n",
        "    # that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations\n",
        "    # and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    # Printing some output after a testing round\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "377llQj-g7IH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to repeat the training process for each epoch.\n",
        "#   In each epoch, the model will eventually see EVERY\n",
        "#   observations in the data\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPZgIVOXibVu",
        "outputId": "b98b6bb1-7c74-4b16-9669-dca73adc8e45"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.311963  [   64/ 5000]\n",
            "loss: 2.226088  [  704/ 5000]\n",
            "loss: 2.166538  [ 1344/ 5000]\n",
            "loss: 2.043823  [ 1984/ 5000]\n",
            "loss: 1.919156  [ 2624/ 5000]\n",
            "loss: 1.897462  [ 3264/ 5000]\n",
            "loss: 1.775369  [ 3904/ 5000]\n",
            "loss: 1.721654  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 75.4%, Avg loss: 1.677561 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.667881  [   64/ 5000]\n",
            "loss: 1.612344  [  704/ 5000]\n",
            "loss: 1.650731  [ 1344/ 5000]\n",
            "loss: 1.566091  [ 1984/ 5000]\n",
            "loss: 1.425802  [ 2624/ 5000]\n",
            "loss: 1.436833  [ 3264/ 5000]\n",
            "loss: 1.346278  [ 3904/ 5000]\n",
            "loss: 1.321608  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 79.9%, Avg loss: 1.312569 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.296955  [   64/ 5000]\n",
            "loss: 1.271047  [  704/ 5000]\n",
            "loss: 1.364068  [ 1344/ 5000]\n",
            "loss: 1.301675  [ 1984/ 5000]\n",
            "loss: 1.145915  [ 2624/ 5000]\n",
            "loss: 1.171075  [ 3264/ 5000]\n",
            "loss: 1.102338  [ 3904/ 5000]\n",
            "loss: 1.100435  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 81.5%, Avg loss: 1.099814 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.072041  [   64/ 5000]\n",
            "loss: 1.079420  [  704/ 5000]\n",
            "loss: 1.189881  [ 1344/ 5000]\n",
            "loss: 1.148116  [ 1984/ 5000]\n",
            "loss: 0.977136  [ 2624/ 5000]\n",
            "loss: 1.007636  [ 3264/ 5000]\n",
            "loss: 0.951243  [ 3904/ 5000]\n",
            "loss: 0.964857  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 82.7%, Avg loss: 0.964974 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.926501  [   64/ 5000]\n",
            "loss: 0.962442  [  704/ 5000]\n",
            "loss: 1.073926  [ 1344/ 5000]\n",
            "loss: 1.050386  [ 1984/ 5000]\n",
            "loss: 0.867043  [ 2624/ 5000]\n",
            "loss: 0.899165  [ 3264/ 5000]\n",
            "loss: 0.849283  [ 3904/ 5000]\n",
            "loss: 0.873037  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 83.7%, Avg loss: 0.872561 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.825940  [   64/ 5000]\n",
            "loss: 0.885113  [  704/ 5000]\n",
            "loss: 0.990825  [ 1344/ 5000]\n",
            "loss: 0.983091  [ 1984/ 5000]\n",
            "loss: 0.790270  [ 2624/ 5000]\n",
            "loss: 0.822450  [ 3264/ 5000]\n",
            "loss: 0.775756  [ 3904/ 5000]\n",
            "loss: 0.806024  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 84.4%, Avg loss: 0.805243 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.752573  [   64/ 5000]\n",
            "loss: 0.830655  [  704/ 5000]\n",
            "loss: 0.927886  [ 1344/ 5000]\n",
            "loss: 0.933871  [ 1984/ 5000]\n",
            "loss: 0.733842  [ 2624/ 5000]\n",
            "loss: 0.765425  [ 3264/ 5000]\n",
            "loss: 0.720041  [ 3904/ 5000]\n",
            "loss: 0.754375  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 84.8%, Avg loss: 0.753883 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.696687  [   64/ 5000]\n",
            "loss: 0.790367  [  704/ 5000]\n",
            "loss: 0.878211  [ 1344/ 5000]\n",
            "loss: 0.896190  [ 1984/ 5000]\n",
            "loss: 0.690631  [ 2624/ 5000]\n",
            "loss: 0.721351  [ 3264/ 5000]\n",
            "loss: 0.676217  [ 3904/ 5000]\n",
            "loss: 0.712935  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 85.3%, Avg loss: 0.713286 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.652639  [   64/ 5000]\n",
            "loss: 0.759383  [  704/ 5000]\n",
            "loss: 0.837754  [ 1344/ 5000]\n",
            "loss: 0.866321  [ 1984/ 5000]\n",
            "loss: 0.656453  [ 2624/ 5000]\n",
            "loss: 0.686217  [ 3264/ 5000]\n",
            "loss: 0.640742  [ 3904/ 5000]\n",
            "loss: 0.678663  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 0.680294 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.616955  [   64/ 5000]\n",
            "loss: 0.734804  [  704/ 5000]\n",
            "loss: 0.803989  [ 1344/ 5000]\n",
            "loss: 0.841994  [ 1984/ 5000]\n",
            "loss: 0.628710  [ 2624/ 5000]\n",
            "loss: 0.657499  [ 3264/ 5000]\n",
            "loss: 0.611365  [ 3904/ 5000]\n",
            "loss: 0.649653  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 85.9%, Avg loss: 0.652887 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.587392  [   64/ 5000]\n",
            "loss: 0.714807  [  704/ 5000]\n",
            "loss: 0.775249  [ 1344/ 5000]\n",
            "loss: 0.821750  [ 1984/ 5000]\n",
            "loss: 0.605710  [ 2624/ 5000]\n",
            "loss: 0.633540  [ 3264/ 5000]\n",
            "loss: 0.586589  [ 3904/ 5000]\n",
            "loss: 0.624645  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 86.2%, Avg loss: 0.629706 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.562443  [   64/ 5000]\n",
            "loss: 0.698195  [  704/ 5000]\n",
            "loss: 0.750391  [ 1344/ 5000]\n",
            "loss: 0.804608  [ 1984/ 5000]\n",
            "loss: 0.586306  [ 2624/ 5000]\n",
            "loss: 0.613208  [ 3264/ 5000]\n",
            "loss: 0.565377  [ 3904/ 5000]\n",
            "loss: 0.602768  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 86.5%, Avg loss: 0.609808 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.541057  [   64/ 5000]\n",
            "loss: 0.684152  [  704/ 5000]\n",
            "loss: 0.728601  [ 1344/ 5000]\n",
            "loss: 0.789883  [ 1984/ 5000]\n",
            "loss: 0.569693  [ 2624/ 5000]\n",
            "loss: 0.595704  [ 3264/ 5000]\n",
            "loss: 0.546986  [ 3904/ 5000]\n",
            "loss: 0.583403  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 86.7%, Avg loss: 0.592513 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.522482  [   64/ 5000]\n",
            "loss: 0.672104  [  704/ 5000]\n",
            "loss: 0.709284  [ 1344/ 5000]\n",
            "loss: 0.777080  [ 1984/ 5000]\n",
            "loss: 0.555288  [ 2624/ 5000]\n",
            "loss: 0.580451  [ 3264/ 5000]\n",
            "loss: 0.530870  [ 3904/ 5000]\n",
            "loss: 0.566092  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 86.7%, Avg loss: 0.577321 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.506164  [   64/ 5000]\n",
            "loss: 0.661635  [  704/ 5000]\n",
            "loss: 0.691991  [ 1344/ 5000]\n",
            "loss: 0.765834  [ 1984/ 5000]\n",
            "loss: 0.542661  [ 2624/ 5000]\n",
            "loss: 0.567019  [ 3264/ 5000]\n",
            "loss: 0.516615  [ 3904/ 5000]\n",
            "loss: 0.550487  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 86.8%, Avg loss: 0.563854 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.491687  [   64/ 5000]\n",
            "loss: 0.652439  [  704/ 5000]\n",
            "loss: 0.676380  [ 1344/ 5000]\n",
            "loss: 0.755866  [ 1984/ 5000]\n",
            "loss: 0.531487  [ 2624/ 5000]\n",
            "loss: 0.555082  [ 3264/ 5000]\n",
            "loss: 0.503905  [ 3904/ 5000]\n",
            "loss: 0.536322  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.551821 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.478734  [   64/ 5000]\n",
            "loss: 0.644284  [  704/ 5000]\n",
            "loss: 0.662183  [ 1344/ 5000]\n",
            "loss: 0.746962  [ 1984/ 5000]\n",
            "loss: 0.521516  [ 2624/ 5000]\n",
            "loss: 0.544390  [ 3264/ 5000]\n",
            "loss: 0.492494  [ 3904/ 5000]\n",
            "loss: 0.523386  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 87.3%, Avg loss: 0.540994 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.467056  [   64/ 5000]\n",
            "loss: 0.636990  [  704/ 5000]\n",
            "loss: 0.649189  [ 1344/ 5000]\n",
            "loss: 0.738953  [ 1984/ 5000]\n",
            "loss: 0.512550  [ 2624/ 5000]\n",
            "loss: 0.534744  [ 3264/ 5000]\n",
            "loss: 0.482182  [ 3904/ 5000]\n",
            "loss: 0.511508  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 87.4%, Avg loss: 0.531191 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.456456  [   64/ 5000]\n",
            "loss: 0.630420  [  704/ 5000]\n",
            "loss: 0.637228  [ 1344/ 5000]\n",
            "loss: 0.731704  [ 1984/ 5000]\n",
            "loss: 0.504434  [ 2624/ 5000]\n",
            "loss: 0.525989  [ 3264/ 5000]\n",
            "loss: 0.472813  [ 3904/ 5000]\n",
            "loss: 0.500553  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 87.5%, Avg loss: 0.522267 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.446778  [   64/ 5000]\n",
            "loss: 0.624462  [  704/ 5000]\n",
            "loss: 0.626160  [ 1344/ 5000]\n",
            "loss: 0.725106  [ 1984/ 5000]\n",
            "loss: 0.497043  [ 2624/ 5000]\n",
            "loss: 0.517997  [ 3264/ 5000]\n",
            "loss: 0.464256  [ 3904/ 5000]\n",
            "loss: 0.490405  [ 4544/ 5000]\n",
            "Test Error: \n",
            " Accuracy: 87.6%, Avg loss: 0.514103 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decide if we are loading for predictions or more training\n",
        "model.eval()\n",
        "# - or -\n",
        "# model.train()\n",
        "\n",
        "# Make predictions\n",
        "pred = model(test_data.__getitem__(1)[0]).argmax()\n",
        "truth = test_data.__getitem__(1)[1]\n",
        "print(f\"This image is predicted to be a {pred}, and is labeled as {truth}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfUrWKgFjBTm",
        "outputId": "3f97f1d2-5f03-4500-d7bb-e22d176997d6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This image is predicted to be a 6, and is labeled as 6\n"
          ]
        }
      ]
    }
  ]
}